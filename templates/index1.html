<!--<!DOCTYPE html>-->
<!--<html>-->
<!--<head>-->
<!--    <title>Webcam Streaming</title>-->
<!--    <script src="//cdnjs.cloudflare.com/ajax/libs/socket.io/4.3.1/socket.io.js"></script>-->
<!--</head>-->
<!--<body>-->
<!--    <h1>Webcam Streaming</h1>-->
<!--    <video id="video" autoplay></video>-->

<!--    <script>-->
<!--        const socket = io.connect('http://127.0.0.1:5000');-->

<!--        // Access the video element-->
<!--        const video = document.getElementById('video');-->

<!--        // Access the video stream from the webcam-->
<!--        if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {-->
<!--            navigator.mediaDevices.getUserMedia({ video: true })-->
<!--                .then((stream) => {-->
<!--                    video.srcObject = stream;-->

<!--                    // Function to send video frames to the server-->
<!--                    function sendFrame() {-->
<!--                        const canvas = document.createElement('canvas');-->
<!--                        const context = canvas.getContext('2d');-->

<!--                        // Set the canvas size to match the video stream-->
<!--                        canvas.width = video.videoWidth;-->
<!--                        canvas.height = video.videoHeight;-->

<!--                        // Draw the current frame on the canvas-->
<!--                        context.drawImage(video, 0, 0, canvas.width, canvas.height);-->

<!--                        // Convert the canvas image to a data URL or Blob-->
<!--                        const frameData = canvas.toDataURL();-->

<!--                        // Send the frame data to the server via SocketIO-->
<!--                        socket.emit('stream_frame', frameData);-->

<!--                        // Schedule the next frame-->
<!--                        requestAnimationFrame(sendFrame);-->
<!--                    }-->

<!--                    // Start sending video frames to the server-->
<!--                    sendFrame();-->
<!--                })-->
<!--                .catch((error) => {-->
<!--                    console.error('Error accessing video stream:', error);-->
<!--                });-->
<!--        } else {-->
<!--            console.error('getUserMedia is not supported in this browser.');-->
<!--        }-->

<!--        // Receive smile detection result from the server-->
<!--        socket.on('smile_detection_result', (smileDetected) => {-->
<!--            if (smileDetected) {-->
<!--                // Display a message or perform some action indicating smile detection-->
<!--                console.log('Smile detected!');-->
<!--            } else {-->
<!--                // Display a message or perform some action indicating no smile detected-->
<!--                console.log('No smile detected.');-->
<!--            }-->
<!--        });-->
<!--    </script>-->
<!--</body>-->
<!--</html>-->
<!--<!DOCTYPE html>-->
<!--<html lang="en">-->
<!--<head>-->
<!--    <meta charset="UTF-8">-->
<!--    <meta name="viewport" content="width=device-width, initial-scale=1.0">-->
<!--    <title>Live Face Recognition</title>-->
<!--    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.1.1/socket.io.js"></script>-->
<!--</head>-->
<!--<body>-->
<!--    <canvas id="faceCanvas" width="640" height="480" style="border:1px solid #000;"></canvas>-->

<!--    <script>-->
<!--        var socket = io.connect('http://' + document.domain + ':' + location.port);-->

<!--        // Get the canvas element and its context-->
<!--        var canvas = document.getElementById('faceCanvas');-->
<!--        var ctx = canvas.getContext('2d');-->

<!--        // Get the webcam video element-->
<!--        var webcamElement = document.getElementById('webcam');-->

<!--        // Event listener for receiving face recognition results and webcam frames-->
<!--        socket.on('face_recognition_result', function(data) {-->
<!--            console.log('Received face recognition result:', data);-->

<!--            // Clear the canvas-->
<!--            ctx.clearRect(0, 0, canvas.width, canvas.height);-->

<!--            // Draw the face detection frame (assuming the frame is available in data)-->
<!--            if (data.frame) {-->
<!--                var img = new Image();-->
<!--                img.onload = function() {-->
<!--                    // Draw the image onto the canvas-->
<!--                    ctx.drawImage(img, 0, 0, canvas.width, canvas.height);-->
<!--                };-->
<!--                img.src = 'data:image/jpeg;base64,' + data.frame; // Assuming frame data is sent as base64 encoded JPEG-->
<!--            }-->
<!--        });-->

<!--        // Send webcam frames to the server-->
<!--        setInterval(function() {-->
<!--            ctx.drawImage(webcamElement, 0, 0, canvas.width, canvas.height);-->
<!--            var frameData = canvas.toDataURL('image/jpeg');-->
<!--            socket.emit('webcam_frame', { frame: frameData });-->
<!--        }, 100);  // Adjust the interval based on your needs-->
<!--    </script>-->
<!--</body>-->
<!--</html>-->
<!DOCTYPE html>
<html>
<head>
    <title>Webcam Streaming</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.1.1/socket.io.js"></script>
</head>
<body>
    <h1>Webcam Streaming</h1>
    <video id="video" autoplay></video>

    <script>
        var socket = io.connect('http://' + document.domain + ':' + location.port);

        // Access the video element
        const video = document.getElementById('video');

        // Access the video stream from the webcam
        if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
            navigator.mediaDevices.getUserMedia({ video: true })
                .then((stream) => {
                    video.srcObject = stream;

                    // Function to send video frames to the server
                    function sendFrame() {
                        const canvas = document.createElement('canvas');
                        const context = canvas.getContext('2d');

                        // Set the canvas size to match the video stream
                        canvas.width = video.videoWidth;
                        canvas.height = video.videoHeight;

                        // Draw the current frame on the canvas
                        context.drawImage(video, 0, 0, canvas.width, canvas.height);

                        // Convert the canvas image to a data URL or Blob
                        const frameData = canvas.toDataURL();

                        // Send the frame data to the server via SocketIO
                        socket.emit('stream_frame', frameData);

                        // Schedule the next frame
                        requestAnimationFrame(sendFrame);
                    }

                    // Start sending video frames to the server
                    sendFrame();
                })
                .catch((error) => {
                    console.error('Error accessing video stream:', error);
                });
        } else {
            console.error('getUserMedia is not supported in this browser.');
        }

        // Receive smile detection result from the server
        socket.on('face_recognition_result', (face_recognition_result) => {
            if (face_recognition_result) {
                // Display a message or perform some action indicating smile detection
                console.log('Received face recognition result:', data);
            } else {
                // Display a message or perform some action indicating no smile detected
                console.log('Received face recognition result:', data);
            }
        });
    </script>
</body>
</html>
